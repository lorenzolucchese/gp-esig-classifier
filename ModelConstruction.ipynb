{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/frtrigg5/A-new-signature-model/blob/main/ModelConstruction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of order and extended order construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "abkdlzGBcdi5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import fbm\n",
    "from lib.data.synthetic import MB_sample\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LqKs1fqyRSGR"
   },
   "outputs": [],
   "source": [
    "begin, end, number, division, dim = 0, 1, 100, 1, 1\n",
    "'''\n",
    "begin = first time steps\n",
    "end = last known time steps\n",
    "division = 1 means we are taking the middle points as new time instants -> L2 = L1 - 1\n",
    "number = L1\n",
    "dim = 1 - one dimensional\n",
    "'''\n",
    "\n",
    "# generating the time steps\n",
    "known_times = torch.linspace(begin, end, number)\n",
    "new_times = torch.zeros(division*(number-1))\n",
    "for i in range(0,(number-1)):\n",
    "  new_times[(division*i):(division*(i+1))] = torch.linspace(known_times[i], known_times[i+1], (division+2))[1:(1 + division)]\n",
    "\n",
    "# Length of known values and new values\n",
    "L1 = known_times.shape[0]\n",
    "L2 = new_times.shape[0]\n",
    "\n",
    "timesteps = torch.cat((known_times, new_times),axis=0)\n",
    "timesteps_sorted, order = torch.sort(timesteps)\n",
    "\n",
    "extended_order = torch.zeros(dim*order.size(0))\n",
    "for i in range(order.size(0)):\n",
    "  extended_order[(i*dim):((i+1)*dim)] = torch.arange(order[i]*dim, (order[i] + 1)*dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construction of the dataset\n",
    "trShape, vlShape, testShape = 1000, 400, 600\n",
    "H = 0.26 # Hurst exponent\n",
    "f = fbm.FBM(number - 1, H)\n",
    "\n",
    "known_times = np.linspace(begin, end, number) #istanti temporali noti\n",
    "div = 1 # quanti nuovi istanti temporali prendere tra due istanti noti\n",
    "new_times = np.zeros(div*(number - 1))\n",
    "for i in range((number-1)):\n",
    "  new_times[(div*i):(div*(i+1))] = np.linspace(known_times[i], known_times[i+1], (div+2))[1:(1+div)]\n",
    "\n",
    "L1 = known_times.size\n",
    "L2 = new_times.size\n",
    "\n",
    "timestamps = np.concatenate((known_times, new_times), axis=0)\n",
    "# time series train\n",
    "dataset_value = np.zeros(shape=[trShape, number])\n",
    "for i in range(trShape//2):\n",
    "  dataset_value[i] = MB_sample(begin, end, number)[0]\n",
    "  dataset_value[i+trShape//2] = f.fbm()\n",
    "\n",
    "# time series validation\n",
    "dataset_value2 = np.zeros(shape=[vlShape, number])\n",
    "for i in range(vlShape//2):\n",
    "  dataset_value2[i] = MB_sample(begin, end, number)[0]\n",
    "  dataset_value2[i+vlShape//2] = f.fbm()\n",
    "\n",
    "# time series test\n",
    "dataset_value3 = np.zeros(shape=[testShape, number])\n",
    "for i in range(testShape//2):\n",
    "  dataset_value3[i] = MB_sample(begin, end, number)[0]\n",
    "  dataset_value3[i+testShape//2] = f.fbm()\n",
    " \n",
    "# adding known and unknown time stamps\n",
    "time_data = np.zeros((trShape, L1 + L2))\n",
    "for i in range(trShape):\n",
    "  time_data[i] = timestamps\n",
    "\n",
    "time_data2 = np.zeros((vlShape, L1 + L2))\n",
    "for i in range(vlShape):\n",
    "  time_data2[i] = timestamps\n",
    "\n",
    "time_data3 = np.zeros((testShape, L1 + L2))\n",
    "for i in range(testShape):\n",
    "  time_data3[i] = timestamps  \n",
    "\n",
    "# full dataset train\n",
    "dataset = np.concatenate((time_data, dataset_value), axis=-1) # full dataset\n",
    "dataset = dataset.astype('float32')\n",
    "\n",
    "# full dataset validation\n",
    "dataset2 = np.concatenate((time_data2,dataset_value2), axis=-1) # full dataset\n",
    "dataset2 = dataset2.astype('float32')\n",
    "\n",
    "# full dataset test\n",
    "dataset3 = np.concatenate((time_data3, dataset_value3), axis=-1) # full dataset\n",
    "dataset3 = dataset3.astype('float32')\n",
    "\n",
    "# label construction\n",
    "y = np.zeros(trShape, dtype='uint8') # label 0 for Brownian Motion, 1 for FBM\n",
    "y[trShape//2:] = 1\n",
    "\n",
    "#label di validation\n",
    "y2 = np.zeros(vlShape, dtype='uint8')\n",
    "y2[vlShape//2:] = 1\n",
    "\n",
    "#label di test\n",
    "y3 = np.zeros(testShape, dtype='uint8') \n",
    "y3[testShape//2:] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "batch = 60\n",
    "training_data = TensorDataset(torch.from_numpy(dataset), torch.from_numpy(y).long())\n",
    "train_loader = DataLoader(training_data, batch_size=batch, shuffle=True)\n",
    "\n",
    "val_data = TensorDataset(torch.from_numpy(dataset2), torch.from_numpy(y2).long())\n",
    "val_loader = DataLoader(val_data, batch_size=vlShape, shuffle=False)\n",
    "\n",
    "test_data = TensorDataset(torch.from_numpy(dataset3), torch.from_numpy(y3).long())\n",
    "test_loader = DataLoader(test_data, batch_size=testShape, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function to calculate accuracy\n",
    "def evaluate_accuracy(model, data_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # No gradient calculation during evaluation\n",
    "        for inputs, labels in data_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)  # Get the predicted class\n",
    "            correct += (predicted == labels).sum().item()  # Count correct predictions\n",
    "            total += labels.size(0)  # Total samples\n",
    "    \n",
    "    accuracy = correct / total * 100  # Calculate accuracy as a percentage\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 5/17 [00:12<00:29,  2.48s/it]"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from lib.model import MyModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "alpha = 1\n",
    "level = 3\n",
    "number_classes = 2\n",
    "C = 1e3\n",
    "a = 1\n",
    "K = 30\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = MyModel(\n",
    "    L1=L1, \n",
    "    L2=L2, \n",
    "    dim=dim, \n",
    "    order=order, \n",
    "    extended_order=extended_order, \n",
    "    alpha=alpha, \n",
    "    level=level, \n",
    "    number_classes=number_classes, \n",
    "    C=C, \n",
    "    a=a, \n",
    "    K=K\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 100\n",
    "patience = 10\n",
    "best_loss = float('inf')\n",
    "early_stopping_counter = 0\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Optimize weights\n",
    "        \n",
    "        running_loss += loss.item()  # Accumulate loss\n",
    "    \n",
    "    # Average loss for the training epoch\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss:.4f}')\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_running_loss = 0.0\n",
    "    with torch.no_grad():  # No gradient calculation for validation\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Compute validation loss\n",
    "            val_running_loss += loss.item()  # Accumulate validation loss\n",
    "\n",
    "    # Average loss for the validation epoch\n",
    "    val_loss = val_running_loss / len(val_loader)\n",
    "    print(f'Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "    # Calculate and print accuracy on validation set\n",
    "    accuracy = evaluate_accuracy(model, val_loader)\n",
    "    print(f'Validation Accuracy: {accuracy:.2f}%')\n",
    "    \n",
    "    # Early stopping\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        early_stopping_counter = 0  # Reset counter if loss improves\n",
    "        print(\"Improved! Saving model...\")\n",
    "        torch.save(model.state_dict(), 'best_model.pth')  # Save the best model\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        if early_stopping_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break  # Stop training if patience is exceeded\n",
    "\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Calculate and print accuracy on validation set\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m evaluate_accuracy(model, \u001b[43mtest_loader\u001b[49m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the best model weights\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Calculate and print accuracy on validation set\n",
    "accuracy = evaluate_accuracy(model, test_loader)\n",
    "print(f'Validation Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "esig-gp-esig-classifier-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
